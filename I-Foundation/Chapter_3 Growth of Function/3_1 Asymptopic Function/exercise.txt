3.1-1
By the defintion of big-theta, let g(x), f(x) be positive function

theta(f(x)) = {h(x) : there exist real positive c1, c2 such thet
                c1*f(x) < h(x) < c2*f(x)}
Then, theta(f(x) + g(x)) = {h(x) : there exist real positive c1, c2 such thet
                            c1*(f(x) + g(x)) < h(x) < c2*(f(x) + g(x))}.
Then let g(x) > c3*f(x), for positive real number that c3 > 0.

Let g(x) = max(f(x), g(x)), and c2 = 1.
Then, g(x) < g(x) + f(x) < 1 * (g(x) + f(x)).

Then, consider when c1 = 1/2*c3, and we have
1/2*c3 (f(x) + g(x)) = 1/2*c3 f(x) + 1/2*c3 g(x)
                     < 1/2 g(x) + 1/2 g(x) (c3 > 1)
                     = g(x).

Since there exist real positive c1 and c2, max(f(x), g(x)) = (belong ) theta(f(x)). The proof is complete. 

3.1 -2
Consider function (n + a)^b. By expand it's term, it is equal to
(n + a)^b = n^b + c1 * n^b-1 + c2 * n^b-2 + ... cb. 

Fix n > max(c1, c2, ... cb).
Then, consider for c2 = b + 1, then 
(n + a)^b < n^b + c1 * n^b-1 + c2 * n^b-2 + ... cb < n^b + n^b .... n^b = b * n^b < (b+1) * n^b.

And for c1 = 1, clearly (n + a)^b > n^b, by consider (n + a)/n > 1.

3.1-3
"The running time of algorithm is at least O(n^2)" means that the lower bound of time complexity is a function such that it's upper bound is n^2. 
However, there are many function's upper bound is n^2, such a function's lower bound build upon a arbitary (function's) upper bound of n^2 is meaningless. 

g(x) > O(n^2) means for function c(x) < cn^2. And g(x) > c(x) may or may not greater than n^2. 


3.1-4
Yes.

3.1-5 
For any two functions f(n) and g(n), we have f(n) = Θ(g(n)) if and only if f(n) = O(g(n)) and f(n) = Ω(g(n)). 

Part 1, 
Suppose f(n) = Θ(g(n)), then by defintion,
there exist real positive c1, c2 such thet c1*g(x) < f(x) < c2*g(x).

Then, clearly f(x) < c2*g(x), and thus f(n) = O(g(n)). 
Similarly,  c1*g(x) < f(x) and thus f(n) = Ω(g(n)).

Part2,
Suppose f(n) = O(g(n)) and f(n) = Ω(g(n). Then there exist real positive, c1, c2 such that
c1*g(x) < f(x) and f(x) < c2*g(x). Combine this two inequality we have

c1*g(x) < f(x) < c2*g(x). And we have f(n) = Θ(g(n)).

3.1-6
The worst case running time of g(x) can be view as max(g(x)).
Similarly, the best case running time is then min(g(x)).

Intutively, if there exist a function such that it is neither max(g(x)) nor min(g(x)), then it is Θ(g(n)). 
By inverse, if a function is Θ(g(n)). It must smaller than max(g(x)) and greater than min(g((x))).

3.1-7
Consider the definition of small o and small w.
The set o(g(n)) n w(g(n)) is {for all c > 0, there exist a const n1 > 0 such that f(n) > c *g(n) and f(n) < c *g(n)}.
Clearly, such f(n) do not exist.